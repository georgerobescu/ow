# ow—thesis chapter #1, user

## From the post-fordist worker to the internet user

There still is a strong desire amongst freelance workers able to spur them to take a solo, independent career and, in doing so, avoiding to be under a boss.

Only for then being under a variety of bosses, being that a company, a client, they themselves even, and so forth.

Post-fordism arose in the early 1970s as a transformation of the current production model of the time, the fordist method applied to the factory, whose pillars were crumbling down due to factors  such as:
> a) diminished profitability of production activities due to labour demands and technical restrictions (problems with managing longer and longer production chains); b) globalisation of economic currents disrupting the management of national economies; c) growing share of social transfers in public spending that propels the inflationary spiral and fosters distributive conflict; d) differentiation of consumption patterns demanding a broader range of supplied use-values.
Post-Fordism–a Contextualisation by Igor Pribac, from Post-Fordism and Its Discontents (2010).

The above are the outlined theories developed by the Regulation School’s (whose most prominent voice was Michel Aglietta), when during the 1970s, the oil crisis, amongst other things, was slowing down the capitalist regime of production.

There were two more schools of thoughts contemporary of the Regulation School: the Neo-Schumpeterians and the Flexible Specialisation approach. Whereas the first was confident that big technological advancements were enough reasons to transform whole societies (religiously finding hope and building faith out of technology), the latter stressed the co-existence of both mass production and the rise of specialised one. For the Neo-Schumpeterians, a lot of agency was given to technological changes, assuming that «socio-political institutional frameworks depend on [these changes]» [^2]. The ‘Flexible Specialisation’ hypothesis, instead, found in the shift of consumers’ desires for a diverse range of products and consequently a transition from mass-industrial production to, more and more, small, highly specialised and flexible firms, the reasons producing the undergoing transformation in the market at the time. Unlike the Regulation School’s four core argumentations reported above though, both Neo-Schumpeterians and Flexible Specialisation’s theories visibly lacked of «the economic-social-political core of the transitional changes» [^1] at the basis of their postulations. Either they saw technology or social factors as the only driving vectors of change, instead of taking into account them both, and including politics as well.

[^1]: Post-Fordism–a Contextualisation by Igor Pribac, from Post-Fordism and Its Discontents (2010).
[^2]: Ibid.

Fresh of the free liberation of desires coming from the 1968, together with the application, for the first time, of neoliberal politics, post-fordism repositioned in the figures of information producers and workers a new faith for the extraction of surplus value.

Common examples of these new job positions are the ones of the journalist, the academic researcher, the designer, etc.

But since the production and usage of informations means indeed the production of language, also figures like the one of the call-center worker are part of this new sphere. And more over, it is also important to remember all the area of care work, meaning affective and emotional labour performed mainly by women in different contexts: waitresses and shopkeepers, care workers, nurses, masseuses, prostitutes and so on.

Affective and emotional labour are not exclusive of these jobs—they are present, in different quantities, in many other form of labour—but for sure they are the most visible and often forgotten type of employments, when talking about post-fordism.

A common element that many, if not all, of these jobs share is giving value to flexibility. When during the late 60s and early 70s flexibility was requested by students-finding-a-job and workers, as part of the transformations taking place in the work field, it was seen by these subjects as a positive and important achievement. They could finally manage, on their on terms, their life and work, they could set their own working schedule, they could decide to have a short-term contract and spend three months at a job, three months in another job, then five other months, for example, travelling (or fulfilling personal aspirations). Ironically, this same lust for flexibility was also happily accepted by the employers. And the capital shifted, in the capturing of the workforce, from the traditional form of brutal, physical energy, sealed in each and every worker; to the working-desire, the desire for work they all had. The desire for self-realisation and, together with this, the energies produced through intellectual-mental labour and from emotional and affective one. This passage marked a transition of employers mainly demanding physical energy, to ask for mental and affective energy on top of the physical one.

> The capitalism the [anti-capitalist] protesters [in May ’68] fought against (...)  was the capitalism of the old spirit. (...) what was set up as an alternative to capitalist production, imagination, life, diversity, freedom, individuality, were the very features offered by the ideologists of new capitalism to form the new spirit of capitalism.
Three Theses on Post-Fordism by Zdravko Kobe, from Post-Fordism and Its Discontents (2010).

Workers were happy not to have fix jobs. This meant going against a long tradition imposed by their family, for which you had to look out for the job of life—which was essential to build indeed a family, a shared life, and reaching a form of stability. Instead, post-fordism introduced words such as part-time job, flexible hours, and in so doing also the idea of precarity.

For many job positions, such as, for e.g., the one of the journalist, the academic, the designer, etc. these new elements could have been taken in such a way that, after some years of paying one’s dues, they may have reached a better position at the office they were working at, or maybe even setting up their own practice. But what would have changed after five years of working at a call-center? Or as a care-worker for and with elderly and disabled people?

One of the biggest critics toward the concept of post-fordism is the fact that it is too localised to very specific geographical contexts (for example, Italy and Japan), to stand as a general paradigm shift on its own. For this reason, many theorists did oppose to such a framework, saying that the fordist production model was only undergoing a structural phase of renovation, rather than living its final crisis. In the same way, other affirms [^3] that the 2008 crisis marked one more milestone in the reversal of the current capitalist, fordist-driven, model of production.

[^3]: Ibid.

A general common element traversing the whole “renovation phase” was the introduction, and more widespread usage, of computers and databases. From the beginning of this economy turn—which for the most part developed in some areas of the western world, as noted above, but can now be seen outsourced to countries of the south-east Asia such as India (cfr. click-farms)—the popularisation of computers and databases were, for sure, essential elements in defining a new working environment, slowly then becoming part of society at large. 

But, leaving unfulfilled the expectations of the Information Society theories’ supporters, who dreamt computers would have given more leisure time to workers and consequently would have improved their engagement in politics, «information technology entered all production sectors–from service to manufacturing industries–and became their integral part without significantly altering the power relations within them». [^4]

[^4]: Ibid.

When in 1997, Maurizio Lazzarato wrote a text on Immaterial Labor, that umbrella term was quite useful to try to define and bring to light a new iteration of what post-fordism became after twenty-five years of development.

> The consumer is no longer limited to consuming commodities (destroying them in the act of consumption). On the contrary, his or her consumption should be productive in accordance to the necessary conditions and the new products. Consumption is then first of all a consumption of information. Consumption is no longer only the "manufacturing" of a product, but a real and proper social process that for the moment is defined with the term communication.

(Maurizio Lazzarato, Immaterial Labor, 1997)

Nowadays, that description has become obsolete, because it is so embedded in the dominant societal order in which we live, that nobody is out of its reach. No more it belongs only to a specialised subset of professions, for the most part contributing to this economic processes, but to anyone who is, in some form, part of society. 

If in moving toward the post-fordist worker subject, Capital began to be interested in accumulating desires—in the form of information production of some kind—while getting a bit more closer and intimate with the subjective sphere of a worker (mental labour, emotional labour, and so on); now with the internet user it is a matter of simply “living” and doing the things you do in your everyday life: Capital needs only that to extract surplus value from your activities.

It is this the connection between the post-fordist worker and the internet user: data is now relevant for the Capital, not only when produced at work and for some very specific purposes, but as data itself, no matter the kind of environment in which it is born. Some value is produced out of it anyway. The precarious position often embedded within the post-fordist subject, even in the position of unemployed, now makes sense. Everybody at home can be capitalised by only browsing the internet. Home has become your phone and computer, rather than a physical fixed site. And labour has been dematerialised both in terms of time, space, and also action.

## Re-understanding conatus as labour in relation to computation

Data is essential to re-understand the user subject. This position implies an expansion of the entities capable of taking part in this role, opening it up to animal, mineral, plant, machinic, algorithmic and bot user, besides the human one. Data becomes the common ground that enables human-user to interface with non-human and in-human users.

For this reason, there must be a shift at the ontological level in the language we use to talk about it: ‘organism’ is incapable of including all the different natures of which the user may be composed of. What does inhuman and ahuman imply, then? Not a desire to define these other natures against the human’s one, through a process of negation with which producing a definition of each entity. Rather, it mostly helps to remind us that the human user is only one possible variant within the user position, stressing a movement of expansion that finds superfluous the connotation organic/inorganic, and instead sites in the terms ‘operative, operational’ and ‘interoperability’ a new kind of language.

It is essential to understand how this shift, from an understanding of user as a living being to one in which its way of being in the world is through data production (*being operative*), traces a line to the concept of conatus.

If conatus is «the effort by which ‘each thing, as far as it can by its own power, strives to persevere in its being» [^1], then does this relate to the user subject in any way? What is the underlaying effort a user must do in order to keep being a user? For a user is a position an entity inhabits: each of this entities have already a conatus of their own even before entering the user position.

[^1]: Frédéric Lordon quoting Benedictus de Spinoza, Ethics, part III, in “Willing Slaves of Capital”.

So what do we mean by «strives to persevere in its being» in connection to a user? Does a user strive to keep producing data and interfacing with other users, in order to avoid falling in dead, non-operative moments? Is there such a thought from the perspective of a user?

There is another frame of conatus that goes more into the idea of iterative, ever-becoming processes. This definition might relate much more to the user position, as something than permits an entity to inhabit differently his her its surrounding and own being. Spinoza says:

> In this life therefore we endeavour [conamur] above all that the body of infancy be changed [mutetur] into another body which is capable of a great many things, and which is related to a mind which is very much conscious of itself, of God, and of things. (Ethics V Proposition 39)
[Conatus: political being and Spinoza](http://criticallegalthinking.com/2015/03/16/conatus-political-being-and-spinoza/), by Stephen Connelly.

With this extended spinozian definition of conatus, the striving to persevere in one’s being, of surviving, means also the continuous effort to adapt and iterate over time. In a sense, then, the question might not only be how much of an effort users have to do in order to keep striving to persevere in their beings, but also how much they are aware of the streams of data production and interaction they are part of.

In the user’s position, labour is not always a conscious performative act, but an ever-happening activity, no matter the effort one’s put in it: once performed, it can be channelled to a specific outcome when the outputted data is used for this or that other reason, task, aim, etc.

Being operative, in this frame, means then not being alive, or being on/off. Instead, it’s a matter of how to build interfaces with other users and producing a different output with the convergence of two, or more, fluxes of data.

In the context of a post-work society where human users will live with a Universal Basic Income, how will the idea of conatus change? With the rising and acknowledgment of many other users, will it turn into a drive for human users to strive to keep being relevant in their inter-operativeness amongst other users?
  
> Worse than being seen as an enemy is not being seen at all. As Eliezer Yudkowsky puts it, “The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.”
From Benjamin Bratton’s [The Black Stack](http://www.e-flux.com/journal/the-black-stack/)

Looking at it in this way, for human users conatus will not be a matter of striving for one’s own sustaining, but striving for building different and better interfaces through which connecting with all the rest of users, in forms that destabilise humanist understanding of *being* in the world, of language and accountability, and so forth.

Conatus becomes a new form of labour, addressing a personal strive to stay together with others, and therefore, in how to use one’s data production to re-position oneself in the world. Interfaces, in parallel, assume the role of survival mechanisms to cope with other users, while being operative as one.

* * *

## User’s agency

How does user’s agency manifest itself?

Unlike one might assume, an entity (algorithmic, mineral, human, etc.) does not correspond to a user in a 1:1 ratio: a subject takes place in the user position fulfilling a set of actions, but in doing this, it is being transformed because of that very position.

To give an example: when we send an email, the user is composed by a part of us (the one thinking and writing the text, choosing a recipient, etc.), the email client and the service provider.

For these reasons, user’s agency doesn’t correspond only to one entity’s desires, but it is shaped by many different agents, forming an array of desires and positions often visible in ways we at first don’t recognise.

For example: in recent years the tracking activities employed by many web services have become part of public opinion’s general topics of discussion. Keeping the same logic described above, it is easier to see how often the intentions we have and want to put into actions—say sending a message in which we talk about particular things—are being captured, read, processed and spitted back to us in the form of tailored ads, tracing a direct relation between the topics of our conversations and the products suggested to us.

Agency is then, like the user position, computational. Data is the common language that permits everyone taking place in the user position, to look for and create interfaces, hence languages, through which to talk and read and listen to other agents, part for example of a platform.

It is clear how, more often than not, we are part of composite users. But instead of thinking about composite users as “other users” and so to “other human beings”, we need to apply the word user to a more vast variety of entities that, for instance, we normally consider tools. Computation makes this easier to understand, because it transforms everything into data-readable and executable formats. Conversely computation, in the process of destroying humanist values and anthropocentric orders of the world, makes no exception or favour to anyone.

(There is a need for a new literacy of computation, after the failed project of cybernetics. Instead of looking for an original cosmological order, where humans and nature will find its perfect and for now lost balance, or silently praying for chaos, we have the chance to step out and aside of the current human language in use, and get closer to a variety of users in ways different than before.)

Interfaces are the places where disputing how user’s agency is being read and performed. Also for this, they become integral in the redefinition of what is life, what is labour, and the transformation of these two spheres into the one of operations, operational and being operative.

(`git` and github.com can be an experiment for a new literacy of computation.)

* * *

## Building status and building history

Whereas oral language tends toward the creation of missing links  (black holes) in the recalling of a fact we used to know, and for this it takes over someone’s memory, computational language—even better than written human language—has a tendency to track everything. It keeps traces of what it has been processed and put them into indexes. Sure, it’s possible to edit those traces, and in so doing producing corrupted links between data sets, but that’s not the point. 

At a structural level, computational language transforms the substantive ‘archive’ into a verb. As a consequence, that’s what we began to do as well, as human users.

`git` works in the same manner, with the difference that the user has to comment after one, or a bunch of, edits performed to a set of files, briefly attesting what happened in doing those changes.

This action is called `git-commit`, and it helps to log more clearly what was updated, deleted and revised, throughout the history of a project.

This mechanism of tracking and commenting, tracking and commenting, forces the user to start adopting a particular mindset—or at least confronting him herself with a thinking mode very well defined (and maybe at odds with his her own).

`git-commit` was conceived as a useful option when working on distributed software projects (e.g. Linux), because for each new improvement or feature added to the codebase, all the rest of the team could easily see what was changed and proposed, then deciding if approving it or not.

If on its original form it works as a way to make someone responsible for his her actions, especially when in relation to a group-based project, the same `git-commit` can be used to add messages with no real connection to the work executed, and building a different, parallel history of its development.

In the context of becoming more aware of how this builds one’s accountability, injecting a disconnected and ‘other’ narrative to describe a very precise but different set of decisions produces confusion and anger in the user reading it. At the same time, it’s a useful thinking to foster unwanted or non-conceived actions (using the commit text to talk in a Q&A manner with the rest of the team; doubling one’s activity between coding a website and writing a narrative about it while developing the project; etc) and freeing this `git` command from its normative function to different parameters and output. In thinking of a new literacy of computation, and using `git` as a first exploration of it, this means stretching and re-contextualising a tool built and conceived to maximise particular tasks, to push it to its most useless and deferential applications. To see where and when it breaks. To create otherness and a more varied understanding. 

What is important to remember, once again, is that this is as well a mechanism to build one’s accountability within a project. Though on github.com users don’t receive marks of any kind (points, or stars, or karma, and so forth), they are very much responsible for every contribution they perform. Since every commit is viewable by anyone accessing the url of that project (except for when a repository is private, but that’s almost never the case for projects users want to spread around), with this action it’s possible to see what happened in the development of a project and when, who did what, how, and for which reasons they accomplished that.

The process of working on a project then, doubly binds with both the process of building a history of that project, and at the same time of building a level of accountability for each contributor who takes part in it.

As an uncommon choice for a social platform’s architecture, on github.com what appears first and foremost are lists of project repositories, then the users working on them. With this shift in the order and visibility of a user, also comes a reverse of hierarchy in the content order of the website: the work is of utmost importance, and users are tiny bits humming in the in-betweens.

github.com’s personal user page nonetheless, has become a portfolio website for many developers, and also for designers dabbing primarily with code (though not only). Much better than any linkedin profile, a github’s user page adamantly reports number of user’s projects created, number of projects that a user has contributed to, popularity of his her projects across the github community (or should we call it group of users? Is there any real connection per se on github?), and complete activity (hours, number of commits, project history, issues, pull requests, ... ) for every project.

Better than any punching-card and office supervisor together could ever do, a user is voluntarily tracked by `git` and actively filling in any useful (or just any) detail left blank for him her to complete.

This sort of platform engagement, is what makes github.com and `git` two products which are becoming to be accepted, used and modified (in its praxis’s orthodoxy) also by non-coders—primarily designers and writers. An expanding user-base makes a particular thinking and working mindset being adopted by different people. The tension produced by stretching defined modalities of making use of `git` and github.com from their new adopters, is also what might foster the beginning of a new literacy of computation.

Not because it makes both tools more humane or less tech-savvy, but on the contrary, because it could be a start to face data production and computation for what it is—a new shift in the making and understanding of the world; while at the same time getting a better sense of what it implies to be part of these  processes.

# ow—thesis chapter #2, platform

(why github.com?)

Github.com is a bizarre platform, because it acts as a possible shift in the understanding of labour, presenting itself, at the same time, as a perfectly integrated layer in the infrastructure of every big or small company.

Drawing from the free and open source software ethos, for which circulation, non-copyrights, collaboration and remixing of code are the founding values of how to frame and to do work, github.com implemented one of the most used tools to put in practice this approach, `git`, at a world-wide level.

Whereas Github the company is born to be sustainable and making profits, selling for this reason private repositories and custom integrations with one’s own private servers, at the same time they are spreading a particular set of ideas all over the commercial internet, some of which are very useful in producing a cultural shift on many areas of what labour means.

Labour on the internet, indeed, often happens as a non-deliberate act, think of the CAPTCHA system for example: a task where users have to prove they are human beings, by typing a short combination of letters and numbers from an image they are provided with. reCAPTCHA uses the typing users perform to prove they are human, to scan and digitise paper books more accurately than a robot could do. Many entities (Google Books, The New York Times’s archives) have used this to successfully convert physical archives of books, and what not, into digital files. If we perceived the CAPTCHA as a riddle, then reCAPTCHA is a form of labour disguised as play.

Github, instead, creates a space where work is shared, complementary, remixed, discussed and improved.

In relation to a possible future scenario defined by a post-work society, platforms like this could be used as a rough blueprint to organise labour in a way, perhaps, more suitable for certain kind of production executed for reasons other than earning a wage. Value will be produced and identified anyway, but will differ from money.

Though they are the first ones not following what they offer, as described below in regard to Github’s copyrights over its own software, at a practical level a Github user has to adapt his her workflow in relation to an environment born from a programming background. Most people joining github.com are part or move around this circle of production, still, such aspect is essential in drawing a line between labour, internet, and its users.

As computation replaces (or doubles) and transforms more and more parts of human life, data becomes the common material produced out of these processes. Far from suggesting that data takes the place of everything that build the world we live in, disembodying bodies of different kinds and abolishing materiality, I am more concerned and curious to explore how it affects the body and how we can read it and use it to readjust our understanding of what constitutes, in this case, work.

If used *en-masse*, Github would be able to familiarise its users to many of the mechanisms taking place on many levels of what constitutes a human life-turned into human-user in the twenty-first century.

For example, data tracking, processing, reading, extracting and its usages is part of what defines the transformation between individuals to dividuals:
> “In the societies of control, on the other hand, what is important is no longer either a signature or a number, but a code: the code is a *password*, while on the other hand the disciplinary societies are regulated by *watchwords* (...) The numerical language of control is made of codes that mark access to information, or reject it. (...) Individuals have become ‘dividuals’, and masses, samples, data, markets, or ‘banks’”
Gilles Deleuze, Postscript on the Societies of Control (1992).

Becoming a mix of codes instead of retaining one’s personality might have seemed the only outcome characterising the new society of information, twenty five years ago.

Assuming that one common element between general human-user activities on the commercial internet and Github.com, is tracking—as a form of measuring and reporting labour activities which took place before, then why not trying to embrace tracking  for real as an everyday activity, to understand it better? What are the processes put in place when this activity is being performed? *In a sense, how does computation, a form of information traceability, look like when it becomes part of one’s existence*?

* * *

(terms and conditions)

To create an account on github.com, the requisites are: 1) to be at least of a teenager age (13 yo) and human, 2) providing a name and email address, 3) using one account per user, unless it’s for a machine user [^1]—in that case it can be hooked up by as many human users as needed, and 4) taking care of one’s password and uploaded content. As a bonus, a human user has the option to create one machine user account.

[^1]: From [github.com’s FAQ](https://developer.github.com/guides/managing-deploy-keys/#machine-users), a machine user is described as an account created by a human-user, and employed to execute automatised tasks set by a human user on a GitHub project.

On Github machine users are acknowledged and given some options. To avoid spam or hacking, and in a way also to implement a norm of human self-responsibility, these accounts cannot be automated in their creation. They have to be set up by other human users. A bot can’t create a bot account on github.com.

The main reason for wanting to use a special machine user account, is to automate tasks when working with more repositories at the same time: speeding up processes, updating a range of submodules [^2], etc.

[^2]: A submodule is a repository (a project folder) linked to another repository, as if it was a sub-folder of the latter.

In the overall exploration of what it means to move towards a posthuman society, where the human is not replaced by better, more advanced, or different entities, but rather realises his blindness in putting at the centre of the world the anthropos as the supreme being, Github’s acknowledgment of machine users looks emblematic: it reinforces Github’s tagline that its platform is ‘How people build software’, assigning proper user’s agency only to human users. Rather than a question of enslavement and or submission, which sounds almost arrogant in its embedding of souls into machine users (cfr. animism), the point is how to find a common ground between human users and machine ones.

When human users assign machine users with tasks they have to complete, the two positions turn into a composite user. This very fact asks for a shift in the way human users see their position as the privileged one, and propose a reframing of their relations with other users through less human-centred design solutions. Again, a human being entering the position of user makes him her leave behind many particularities constituting one’s personal self, to inhabit a subjectivity of a different kind. When I assume the role of a user, I am not my full self, but portions of it depending on the task at hand. The common ground I foresee might be necessary to look for, between human users and machine users on github.com, is due to the fact that they are both constituted by some shared elements: a set of available actions and data. The nature at the basis of each user is determining in the way they interact with each other, but should not become a ‘box’ that helps to avoid better and different interoperativity between them.

For this, I don’t yet see problematic GitHub’s need for human authentication when creating a new machine user, because the platform is born to organise and shared human labour first of all. But slowly, it could be used to actively promote a gradual transition toward a common language of data and its computation between human and machine users.

The rising of bots to help human beings with mundane, boring, repetitive, or very complex computational tasks is telling in the measure each of its human creators use them for.

On a more basic level, many of this bots are often dummy and troll experiments, set up for example, to make a user’s followers growing, or spamming all repositories containing a particular component in their architecture.

In this case, human user’s agency still prevails all over. But as it happens on Twitter since a while, where bots of different scopes are populating the platform and enriching the streams of many human users who follow them—from literary experiment, to snarky cut-up tweets, to any other variation in topic and form—which shape could this take on Github?

A shift in the current situation, would imply a recalibration of usership. To be very brutal, we could see all technological infrastructures as using human users not as agents, but as components of larger mechanisms. Usership is defined both by using as well as by being used. Being operative is exactly that: transmitting something, receiving something else. In these two actions, informing and deforming the material being passed on.

Github.com is born as a way to spread, facilitate and automate this operativity. Setting up rules where human users are the gatekeepers of the platform, makes sense in a culture still very much imbued with humanist values: it is, nonetheless, a process that could bring human users closer with users of other natures. To give “only” human users permission to add machine users, encounter them and being in relation with them is maybe the way to go in this initial phase. Not to make this a reason to let human users tame machine users, but, effectively, the other way around.

Part of Github’s architecture consists of specific features added as extensions of `git`’s existing structure. 

The main pillars around which github.com is built are:
* Code
* Issues
* Pull Requests

*Code* is the default section and displays: a) the commit history of the project folder—a list of the files sitting in the root level of the folder, with a brief text next to each file/folder describing which change has been made; b) the readme file—the text of presentation for the project, usually giving a general overview of the work and some technical information of how it has been built and how to use it. 

While the commit history is at the basis of `git`’s architecture, and it’s possible to visualise it when working with `git` on the Terminal as well; the readme file becomes so much central only on github.com, acting as the welcoming text for a new user visiting the project page.

On GitHub users are free to `fork` (cloning to their account) every repository they have access to (they can be public or private), and with this action using and or contributing to the project. 

A general usage of the platform consist in working on a project in your local hard-drive and synchronising it to a project with the same name on github.com. Every now and then `forking` other projects on GitHub that might be helpful for the work one is doing, while at the same time maybe having contributors improving one’s project’s code.

This fluid exchange and improvements of code is part of the two most used and quintessential features of GitHub, *Issues* and *Pull Requests*.

*Issues* gives users the possibility to report problems of any kind that they have encountered in the usage of a particular project repository.

It serves as the help & assistance centre of a project, with the benefit than anyone who wants to help or have an answer to what is posted, can participate. In fact, the creator of the repository is not the only one in charge and or in power of that position.

The other useful area, parallel to the Issues section, is *Pull Requests*.

Whereas in Issues a user would, and should only post, problems, in Pull Request users can suggest new features and improvements for the project. It’s not that uncommon for a reported bug or missing feature, to transition from Issues to Pull Requests and being transformed into a feature request. At its best, this structure lets swing from the two sites of discussion very smoothly, improving either what exists, or pushing for new expansions.

There are three more tabs that builds each project repository on github.com, *Pulse*, *Graphs*, and *Wiki*. The first shows a dashboard with all the working activities which took place so far. The second is a tab with the list of contributors to the project and other statistic diagrams displaying how operative the project has been until that moment. The third is a place where to extend the readme file (the introduction text of a project) with more detailed information. In describing the peculiarities of github.com though, these three tabs, while useful, took less weight in the success of the platform.

Being Issues and Pull Requests the two areas of conversation and exchange, one think of how to avoid bureaucratisation on the platform. There are tons of software that sits on top of github.com to better organise, filter, assign, label, and resolve issues on GitHub.

Similarly, the amounts of ad-hoc solutions, fragmentation of the apparatus into smaller tasks, and cyclical proposals coming from GitHub users, suggests how the Issues tool has become essential within the platform and, exactly because of this, in need of many face-liftings—if not of a structural rethinking.

The implementation of a quick-access option to the emojis keyboard, when typing `:` + any letter or number, lets users dealing with Issues and or Pull Requests with ease, showing their approval or disregard of a particular opinion, or of a new implemented feature, with a couple of strokes.

With an open ended amount of users possibly interacting on many popular open-source projects, the level of time wasted by the maintainers of these repositories just to check a new notification—reporting yet another user adding ‘+1/👍/me too’—grows huger and huger.

Since this way to show support is quite widespread, a group of GitHub users proposed to implement a proper voting system, able to transform the above reactions into +1 or -1.

These users, tired of how the platform functions, and having to manage big open-source projects hosted on it, published an open letter directed to GitHub Inc, in the form of a new repository project. [^3]

[^3]: Here the submission—[Dear Github](https://github.com/dear-Github/dear-Github).

In it, they suggest how they would like the Issues tool to work, reaching a peak when they surf over the fact that, if github.com would be open source, they would be more than happy to help with the implementation of what they have been asking for. So many nervous grins flirting with a company which, in less then ten years, now hosts the majority of the open source projects on the commercial internet.

This perfectly resonate with the history of the open source community, at the schism-level with the free software group. Born as one and the same, and divided from the original group after almost fifteen years of being together, the new formed open source group stepped away from the free software movement for some disagreements at the ethical level. While often the two groups are taken for the same thing, they differ in their philosophy:
>   (...) whereas free software is always also open source, open source software does not necessarily have to be free software. That is, software can be open source without granting its users the additional freedoms that free software guarantees.
LINFO, [Open Source Definition](http://www.linfo.org/open_source.html).

What are these additional freedoms? Open source software cares mostly that a program be at no monetary cost and that its source code can be inspected. At a level of what one can do with the source code, though, free software lets a user not only read it (as open source software does), but also modify it and redistribute it without restrictions—under the rule that it will remain free and modifiable also for other users.

For this, free software sees itself as a social movement advocating freedom in its multifold manifestations; open source software aligns itself to only a ‘practical’ development methodology, ignoring ethical concerns.

Comparing this quick sketch of the difference between free software and open source software, it is clear how this positively re-affirms the open source movement’s aspirations at the time of their split with the free software group: to appeal the corporate-business-y environment. Making them use free software indeed, was perceived as pitching a poorly made product to the high society, whereas the industry-informed ethos of the open source group was fitting much better, since their attitude privileged well made products and avoiding to deal with ethical questions as much as possible.

On their side, GitHub Inc. replied to the open letter published by the big group of developers mentioned above, saying that they not only are listening to their requests (finally giving an answer to the their emails after two years of silence), but are also working on some extra features to rethink the Issues section on the platform.

That’s how your roll it out.

* * *

(git’s decentralised structure and GitHub’s centralised one)

Github.com acts as an interface of `git`, making the activity of working together on the same project, and sharing new code, easier.

Even though it is possible to set up one’s own server with `git` installed on it, and create a web interface to facilitate the exchange and collaboration of projects, what github.com offers is—as many other internet services and social platforms—the possibility to focus on what you want to do and not investing time in the underlaying infrastructure governing those very activities.

Perversely, github.com has become the most recognised and main used website for sharing `git`-based workflows, as well as the biggest website hosting open source projects. The perversion lies in the fact that in becoming this, in the first case it is going against the very principles and architecture employed (and suggested) by `git`, while in the second instance it is finding itself in a bizarre situation.

The two main factors that put GitHub Inc. in the above position are:
1. centralisation of the decentralised-by-design git’s infrastructure
2. copyrights over github.com’s software

In its inception, and to put it cynically, `git` is decentralised because its creator, Linus Torvald, was in need to get patches from the various developers helping him with the development of Linux. Originally, `git` was built as a reaction to some problems the Linux project had while being hosted on BitKeeper—a popular Version Control System (like github.com is). After Andrew Tridgell, a computer programmer involved in the free software scene, tried to build a free version of BitKeeper (which is proprietary software), part of the Linux project was treated, by BitKeepers itself, to not being freely stored on BitKeepers’ servers anymore. For this, Torvald, in need of a replacement, decided to create a free and better implementation of the service to use for his own needs.

Version Control Systems are divided in those implementing a centralised architecture, and those adopting a decentralised and distributed one. In the former case, users have to work with the same copies of files on a central server. If the server has problems, users working with it will automatically suffer as well. `git`, instead, is a distributed system, where each user has its own copy of the same project, and for this, it is, potentially, also a decentralised one, as users are spread all over the network. It is only potentially decentralised, because it requires that each user would set up his her own `git` server, and would give access to it to other users as well.

Still, this multiplicities of Linux enthusiasts were perfect for Torvald: more contributions, more choices to pick from or to discard.

The problem with github.com copyrighting the software that makes it run is that, unlike any other repository hosted on its platform, GitHub’s own project repository can’t be duplicated and used, and improved, and modified—it’s not even listed along the other project on the platform.

Besides this being at odd with the fundamentals of `git`, it makes it very hard to create a relay effect for which, when github.com is having some issues, another ‘copy’ of it takes over and keeps the service up and running. If GitHub is down, a big chunk of the internet is down as well. Of course for this to happen, first GitHub should be open sourced, whereas now it’s not; and second, many GitHub users should invest a small amount of money in duplicating on their personal servers a perfect copy of the platform’s software and make it accessible to other GitHub user. Ideally then, if we would stretch this current limitation (github.com’s biggest one?), there would be an easy option, in the configuration panel of each user, through which setting up a copy of GitHub’s software on one’s own server by only following some easy steps (or even with a 1-click button).

[GitTorrent](http://blog.printf.net/articles/2015/05/29/announcing-gittorrent-a-decentralized-Github/), a project by Chris Ball, aims exactly at resolving this problem. Using BitTorrent as its peer 2 peer decentralised network infrastructure, GitTorrent, in its first experiment, would be able to create this relay effect I sketched above. What GitTorrent proposes, is to make `git` decentralised for real—since the necessary architecture is there already, but the infrastructure to do it still requires quite some effort to be well implemented and kept up to date.

In the case GitHub’s servers were down, GitTorrent would permit the user of the former platform to still access it, because each of them would be using GitTorrent, and so putting online, in a peer 2 peer network (through BitTorrent), their local repositories. It’s the same when you download a movie through torrent and then let the torrent application still on, so other users can munch bits of the movie’s file as well, and complete the download process. This already happens when using GitHub: a user have (or should have) a local copy of the project on his her hard-disk, and should synchronise it with GitHub when making new progress. GitTorrent moves away from this infrastructure [^4], by using a decentralised network architecture (BitTorrent) which relies on users themselves and the internet network, rather than on an unique site of storage.

[^4]: The project is already quite ambitious and covers—as well as made use of—other areas and technologies: for example it employs blockchain to distribute usernames to adopt on the network. [Here the article](http://blog.printf.net/articles/2015/05/29/announcing-gittorrent-a-decentralized-Github/).

As Bratton says [^5], platforms, acting as a third site between the State and the Market, both centralise some functions and decentralise others. What GitHub did, was to centralise `git`’s distributed architecture into a common space for anyone to join. While this have brought many benefits, if only the general spreading and higher relevance of open source projects, on the other side it’s a movement undermining the very reasons which made Linus Torvald leaving BitTorrent, for something non-dependant on a central infrastructure.

[^5]: [The Politics Of Platform Technologies—Benjamin Bratton](https://www.youtube.com/watch?v=aeWr70c1_mE).

GitHub’s merit, even if only temporary, might be to have created the conditions for a massive transition toward a truly distributed and decentralised `git` network. But as with many other projects of the same kind, the desirability to start adopting, promoting, and co-developing GitTorrent, lies in how easy to setup and to maintain it is. This directly affects the perceived easiness of its use. In the attempt of spreading a new literacy of computation also through `git`, one which is self-reflexive—through one’s adoption and usage of it—of the circumstances that makes one’s usership up, the initial level of interfaciality between user and user, or user and tool, is going to determine the adoption of it or not.

Since the thinking and making of new interfaces between users is the new conatus as work, when data and computation become the common material through which interacting between users of different nature, github.com is making a good job in expanding its platform to new users. In parallel, a new iteration of it in the form of GitTorrent, could bring and spread more literacy on a technical level, while implementing different and better ethical values at the same time. *How would this set of values position themselves in the sketching of a posthuman ethics, though*?